# ğŸ“Š MigraÃ§Ã£o de MAPE para WMAPE

**Data:** Janeiro 2026 (Atualizado: Fevereiro 2026)
**Status:** âœ… IMPLEMENTADO
**VersÃ£o:** 2.1

---

## ğŸ¯ O Que Mudou?

A mÃ©trica principal de acurÃ¡cia do sistema foi **atualizada de MAPE para WMAPE** (Weighted Mean Absolute Percentage Error).

### ANTES (MAPE)
```
MAPE = (1/n) Ã— Î£ |actual - predicted| / |actual| Ã— 100
```
- Trata todos os produtos igualmente
- Produto de 1 unidade tem mesmo peso que produto de 100 unidades
- Pode ser distorcido por produtos de baixo volume

### DEPOIS (WMAPE)
```
WMAPE = Î£|actual - predicted| / Î£|actual| Ã— 100
```
- Pondera erros pelo volume de vendas
- Produtos de alto volume tÃªm peso proporcional Ã  sua importÃ¢ncia
- Mais representativo para anÃ¡lise de varejo

### BIAS (DireÃ§Ã£o do Erro)
```
BIAS = Î£(predicted - actual) / Î£|actual| Ã— 100
```
- Indica se o modelo tende a **superestimar** (BIAS > 0) ou **subestimar** (BIAS < 0)
- BIAS positivo = previsÃµes maiores que valores reais
- BIAS negativo = previsÃµes menores que valores reais
- BIAS prÃ³ximo de 0 = modelo equilibrado

---

## ğŸ’¡ Por Que WMAPE Ã© Superior?

### Exemplo PrÃ¡tico

| Produto | Venda Real | PrevisÃ£o | Erro Absoluto | APE (MAPE) |
|---------|------------|----------|---------------|------------|
| A       | 1 un       | 2 un     | 1 un          | 100%       |
| B       | 100 un     | 101 un   | 1 un          | 1%         |

**MAPE (mÃ©dia simples):**
```
MAPE = (100% + 1%) / 2 = 50.5%
```
âŒ **Resultado distorcido!** O produto A (1 unidade) tem mesmo peso que B (100 unidades).

**WMAPE (ponderado por volume):**
```
WMAPE = (1 + 1) / (1 + 100) Ã— 100 = 1.98%
```
âœ… **Resultado correto!** O erro de 1 unidade Ã© pequeno no contexto do volume total.

---

## ğŸ”§ O Que Foi Alterado?

### 1. Core: accuracy_metrics.py
- âœ… Nova funÃ§Ã£o `calculate_wmape()`
- âœ… FunÃ§Ã£o `calculate_mape()` marcada como **DEPRECADA**
- âœ… `walk_forward_validation()` retorna WMAPE como mÃ©trica principal
- âœ… `evaluate_model_accuracy()` usa WMAPE nos cÃ¡lculos
- âœ… `format_accuracy_report()` exibe WMAPE

### 2. Backend: app.py
- âœ… VariÃ¡vel `mape` renomeada para `wmape`
- âœ… Coluna de saÃ­da `MAPE` alterada para `WMAPE`
- âœ… modelo_info usa `wmape` em vez de `mape`

### 3. Frontend: templates/index.html
- âœ… Card "MAPE MÃ©dio" â†’ "WMAPE MÃ©dio"
- âœ… ExplicaÃ§Ã£o atualizada: "Mede a acurÃ¡cia ponderada por volume"

### 4. Frontend: static/js/app.js
- âœ… VariÃ¡vel `mapeMedia` â†’ `wmapeMedia`
- âœ… FunÃ§Ã£o `getMapeColor()` â†’ `getWmapeColor()`
- âœ… Filtro `p.MAPE` â†’ `p.WMAPE`
- âœ… Texto explicativo atualizado

### 5. DocumentaÃ§Ã£o
- âœ… Novo arquivo: `WMAPE_IMPLEMENTACAO.md`
- ğŸ“ Arquivos a atualizar:
  - `README.md`
  - `CORRECAO_MAPE_COMPLETA.md` â†’ renomear
  - `MAPE_THRESHOLD_CHANGE.md` â†’ renomear
  - `VALIDACAO_ALERTAS.md`
  - `MELHORIAS_IMPLEMENTADAS.md`

---

## ğŸ“ˆ Faixas de InterpretaÃ§Ã£o

As faixas de qualidade **permanecem as mesmas**:

| WMAPE      | ClassificaÃ§Ã£o | Cor    |
|------------|---------------|--------|
| < 10%      | Excelente     | Verde  |
| 10-20%     | Boa           | Azul   |
| 20-30%     | AceitÃ¡vel     | Laranja|
| 30-50%     | Fraca         | Vermelho|
| > 50%      | Muito Fraca   | Vermelho Escuro|

---

## ğŸ”„ Compatibilidade

### MAPE Ainda EstÃ¡ DisponÃ­vel
```python
# WMAPE (recomendado)
results = walk_forward_validation(data, model_name, horizon)
wmape = results['wmape']

# MAPE (legacy - mantido para compatibilidade)
mape = results['mape']
```

**Motivo:** Permite comparaÃ§Ã£o com sistemas antigos e transiÃ§Ã£o gradual.

---

## ğŸ“Š Impacto Esperado

### Produtos Alto Giro
- WMAPE serÃ¡ **similar ou menor** que MAPE
- Erros absolutos maiores, mas percentualmente corretos

### Produtos Baixo Giro
- MAPE inflava artificialmente o erro mÃ©dio
- WMAPE reflete melhor a realidade do negÃ³cio

### Exemplo Real
```
Antes (MAPE):
- Produto A (1000 un/mÃªs): 5% erro
- Produto B (10 un/mÃªs): 50% erro
- MAPE mÃ©dio: (5% + 50%) / 2 = 27.5% âŒ

Depois (WMAPE):
- Mesmos produtos
- WMAPE: (50 + 5) / (1000 + 10) Ã— 100 = 5.4% âœ…
```

---

## âœ… Checklist de ImplementaÃ§Ã£o

- [x] Implementar `calculate_wmape()` em accuracy_metrics.py
- [x] Deprecar `calculate_mape()` com aviso
- [x] Atualizar `walk_forward_validation()` para retornar WMAPE
- [x] Atualizar `evaluate_model_accuracy()` para usar WMAPE
- [x] Atualizar `format_accuracy_report()` para exibir WMAPE
- [x] Alterar app.py para usar WMAPE
- [x] Atualizar templates/index.html
- [x] Atualizar static/js/app.js
- [x] Corrigir cÃ¡lculo do fator de tendÃªncia (comparar perÃ­odos equivalentes ano-a-ano)
- [x] Testar com dados reais (WMAPEâ‰ BIAS confirma funcionamento correto)
- [ ] Atualizar documentaÃ§Ã£o completa
- [ ] Commit e push para GitHub

---

## ğŸ”§ CorreÃ§Ã£o do CÃ¡lculo de TendÃªncia (Fevereiro 2026)

### Problema Identificado
O WMAPE e o BIAS estavam mostrando valores idÃªnticos (ex: 45.5% ambos), o que indicava que **todas as previsÃµes tinham o mesmo sinal de erro** (todas superestimavam ou todas subestimavam).

### Causa Raiz
O fator de tendÃªncia era calculado comparando a **primeira metade vs segunda metade** da base histÃ³rica:
```python
# ANTES (problemÃ¡tico)
media_primeira_metade = sum(valores_base[:meio]) / meio
media_segunda_metade = sum(valores_base[meio:]) / (len - meio)
fator_tendencia = media_segunda_metade / media_primeira_metade
```

Este mÃ©todo nÃ£o capturava a **mudanÃ§a real ano-a-ano**. Se 2024 teve vendas maiores que 2025, o backtest continuava prevendo valores de 2024, gerando erros sistematicamente positivos.

### SoluÃ§Ã£o Implementada
Novo cÃ¡lculo que compara **perÃ­odos equivalentes ano-a-ano**:
```python
# DEPOIS (corrigido)
for data_str in datas_base:
    # Para cada perÃ­odo, encontrar o mesmo mÃªs/semana do ano anterior
    valor_atual = valores_base[i]
    valor_ano_anterior = vendas_por_data.get(data_aa_str, 0)

    if valor_aa > 0 and valor_atual > 0:
        soma_valores_ano_recente += valor_atual
        soma_valores_ano_anterior += valor_aa
        pares_encontrados += 1

# Calcular fator baseado em perÃ­odos equivalentes
if pares_encontrados >= 3:
    fator_tendencia = soma_valores_ano_recente / soma_valores_ano_anterior
```

### Resultado
- **Antes:** WMAPE = 45.5%, BIAS = 45.5% (idÃªnticos = erro sistemÃ¡tico)
- **Depois:** WMAPE = 14.5%, BIAS = 13.8% (diferentes = erros mistos)

O fator de tendÃªncia agora reflete corretamente se as vendas estÃ£o **crescendo ou diminuindo** em relaÃ§Ã£o ao ano anterior, resultando em previsÃµes mais equilibradas.

---

## ğŸ“Š Metodologia do Backtest

O backtest (validaÃ§Ã£o com perÃ­odo de teste) usa a seguinte metodologia:

### DivisÃ£o dos Dados
```
HistÃ³rico total â†’ 75% Base + 25% Teste
```

### CÃ¡lculo da PrevisÃ£o para PerÃ­odo de Teste

1. **Buscar mesmo perÃ­odo do ano anterior**
   - Para cada perÃ­odo de teste, procurar o mesmo mÃªs/semana do ano anterior no histÃ³rico
   - Exemplo: Para prever Ago/25, buscar Ago/24

2. **Aplicar fator de tendÃªncia**
   - Calcular tendÃªncia comparando primeira e segunda metade da base
   - `fator_tendencia = mÃ©dia_segunda_metade / mÃ©dia_primeira_metade`
   - Limitado entre **0.6 (-40%)** e **1.5 (+50%)** para evitar distorÃ§Ãµes

3. **CÃ¡lculo da previsÃ£o**
   ```
   SE valor_ano_anterior > 0:
       previsao = valor_ano_anterior Ã— fator_tendencia
   SENÃƒO:
       previsao = mÃ©dia_base Ã— fator_sazonal
   ```

### Por que essa abordagem?
- Respeita a sazonalidade natural (mesmo perÃ­odo = mesmo comportamento)
- Considera tendÃªncia de crescimento/queda
- Evita superestimaÃ§Ã£o quando a base inclui picos de outros meses

---

## ğŸ§ª Como Testar

```bash
# 1. Testar cÃ¡lculo WMAPE
python -c "
from core.accuracy_metrics import calculate_wmape, calculate_mape

actual = [1, 100]
predicted = [2, 101]

mape = calculate_mape(actual, predicted, min_value=0)
wmape = calculate_wmape(actual, predicted, min_value=0)

print(f'MAPE:  {mape:.2f}%')  # ~50.5%
print(f'WMAPE: {wmape:.2f}%') # ~1.98%
"

# 2. Rodar previsÃ£o completa
python app.py
# Verificar que cards exibem "WMAPE MÃ©dio"

# 3. Validar mÃ©tricas
# Acessar /demanda e verificar valores
```

---

## ğŸ“š ReferÃªncias TÃ©cnicas

### Artigos sobre WMAPE vs MAPE
- **Hyndman, R.J.** (2014): "Another look at forecast accuracy metrics for intermittent demand"
- **Kolassa, S.** (2016): "Why the MAPE is a terrible metric for low-volume data"

### ConclusÃ£o dos Estudos
> "Para dados de varejo com mix de produtos de alto e baixo volume, WMAPE Ã© superior ao MAPE por ponderar adequadamente os erros pelo impacto financeiro de cada produto."

---

## ğŸ“ GlossÃ¡rio

- **MAPE:** Mean Absolute Percentage Error (nÃ£o ponderado)
- **WMAPE:** Weighted Mean Absolute Percentage Error (ponderado)
- **APE:** Absolute Percentage Error (erro individual)
- **PonderaÃ§Ã£o:** Atribuir pesos proporcionais ao volume de vendas
- **Min Value:** Threshold mÃ­nimo para incluir na mÃ©trica (default: 2.0)

---

## ğŸš€ PrÃ³ximos Passos

1. âœ… ImplementaÃ§Ã£o completa (cÃ³digo + interface)
2. â³ ValidaÃ§Ã£o com dados reais
3. â³ AtualizaÃ§Ã£o de toda documentaÃ§Ã£o
4. â³ Commit e push para GitHub
5. ğŸ“ Comunicar mudanÃ§a aos usuÃ¡rios
6. ğŸ“Š Comparar WMAPE vs MAPE em produÃ§Ã£o (primeiras semanas)

---

**Desenvolvido por:** Claude Code + Valter Lino
**MÃ©trica Principal:** WMAPE (Weighted MAPE)
**Status:** Implementado e pronto para testes
