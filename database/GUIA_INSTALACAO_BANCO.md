

# ðŸ—„ï¸ Guia de InstalaÃ§Ã£o e ConfiguraÃ§Ã£o do Banco de Dados

**Objetivo:** Estruturar dados (CSV/Excel) em banco de dados PostgreSQL

**Formatos Aceitos:** CSV, XLSX, XLS

---

## ðŸ“‹ Ãndice

1. [Por Que Usar Banco de Dados?](#por-que-usar-banco-de-dados)
2. [InstalaÃ§Ã£o do PostgreSQL](#instalaÃ§Ã£o-do-postgresql)
3. [CriaÃ§Ã£o do Banco](#criaÃ§Ã£o-do-banco)
4. [PreparaÃ§Ã£o dos Arquivos](#preparaÃ§Ã£o-dos-arquivos)
5. [ImportaÃ§Ã£o dos Dados](#importaÃ§Ã£o-dos-dados)
6. [ValidaÃ§Ã£o](#validaÃ§Ã£o)
7. [IntegraÃ§Ã£o com a Ferramenta](#integraÃ§Ã£o-com-a-ferramenta)

---

## ðŸŽ¯ Por Que Usar Banco de Dados?

### Problemas dos CSVs:
âŒ Lento para grandes volumes (>100MB)
âŒ Dados duplicados (mesmos cadastros em vÃ¡rios arquivos)
âŒ DifÃ­cil manter consistÃªncia
âŒ NÃ£o tem relacionamentos
âŒ NÃ£o tem Ã­ndices (busca lenta)
âŒ MemÃ³ria: carrega tudo de uma vez

### Vantagens do PostgreSQL:
âœ… **Performance:** Queries otimizadas com Ã­ndices
âœ… **Escalabilidade:** MilhÃµes de registros sem problemas
âœ… **Relacionamentos:** Integridade referencial
âœ… **Particionamento:** HistÃ³rico dividido por ano
âœ… **Views Materializadas:** Cache de agregaÃ§Ãµes
âœ… **Backup/Restore:** Ferramentas nativas
âœ… **Concurrent:** MÃºltiplos processos acessando

---

## ðŸ’¿ InstalaÃ§Ã£o do PostgreSQL

### Windows:

1. **Download:**
   - Acesse: https://www.postgresql.org/download/windows/
   - Baixe o instalador (versÃ£o 14 ou superior)

2. **InstalaÃ§Ã£o:**
   - Execute o instalador
   - **Senha do superusuÃ¡rio (postgres):** Anote bem!
   - Porta padrÃ£o: `5432`
   - Locale: `Portuguese, Brazil`

3. **Verificar InstalaÃ§Ã£o:**
   ```cmd
   psql --version
   ```
   Deve retornar: `psql (PostgreSQL) 14.x`

### Ferramentas Opcionais:

**pgAdmin 4** (Interface GrÃ¡fica)
- JÃ¡ vem com o instalador do PostgreSQL
- Permite visualizar tabelas, executar queries, etc

**DBeaver** (Alternativa)
- Download: https://dbeaver.io/
- Mais leve que pgAdmin

---

## ðŸ—ï¸ CriaÃ§Ã£o do Banco

### OpÃ§Ã£o 1: Via pgAdmin (GrÃ¡fico)

1. Abrir pgAdmin 4
2. Conectar ao servidor local (senha que vocÃª criou)
3. Right-click em "Databases" â†’ Create â†’ Database
4. Nome: `demanda_reabastecimento`
5. Encoding: `UTF8`
6. OK

### OpÃ§Ã£o 2: Via Terminal (Linha de Comando)

```cmd
# Conectar ao PostgreSQL
psql -U postgres

# Criar banco
CREATE DATABASE demanda_reabastecimento
    WITH
    ENCODING = 'UTF8'
    LC_COLLATE = 'Portuguese_Brazil.1252'
    LC_CTYPE = 'Portuguese_Brazil.1252';

# Sair
\q
```

### Criar as Tabelas:

```cmd
# Navegar atÃ© a pasta do projeto
cd C:\Users\valter.lino\Desktop\Treinamentos\VS\previsao-demanda

# Executar script SQL
psql -U postgres -d demanda_reabastecimento -f database\schema.sql
```

âœ… Isso cria TODAS as tabelas, Ã­ndices e views!

---

## ðŸ“‚ PreparaÃ§Ã£o dos Arquivos

### ðŸ“‹ Formatos Aceitos

O script de importaÃ§Ã£o aceita **trÃªs formatos**:
- âœ… **CSV** (`.csv`) - Recomendado para grandes volumes
- âœ… **Excel Moderno** (`.xlsx`) - Excel 2007+
- âœ… **Excel Antigo** (`.xls`) - Excel 97-2003

VocÃª pode misturar formatos! Exemplo:
- `cadastro_produtos.xlsx` (Excel)
- `historico_vendas.csv` (CSV)
- `estoque_atual.xls` (Excel antigo)

### ðŸ“ Estrutura de Pastas

A pasta `data_import` jÃ¡ foi criada. Coloque seus arquivos lÃ¡:

```
C:\Users\valter.lino\Desktop\Treinamentos\VS\previsao-demanda\
â””â”€â”€ data_import\
    â”œâ”€â”€ cadastro_produtos.[csv|xlsx|xls]
    â”œâ”€â”€ cadastro_fornecedores.[csv|xlsx|xls]
    â”œâ”€â”€ cadastro_lojas.[csv|xlsx|xls]
    â”œâ”€â”€ estoque_atual.[csv|xlsx|xls]
    â”œâ”€â”€ pedidos_abertos.[csv|xlsx|xls]
    â”œâ”€â”€ transito_atual.[csv|xlsx|xls]
    â”œâ”€â”€ historico_vendas.[csv|xlsx|xls]
    â”œâ”€â”€ historico_estoque.[csv|xlsx|xls]
    â”œâ”€â”€ historico_precos.[csv|xlsx|xls]
    â””â”€â”€ eventos_promocionais.[csv|xlsx|xls]
```

ðŸ’¡ **Importante:** VocÃª NÃƒO precisa ter todos os arquivos! O script importa apenas os que encontrar.

### ðŸ“‹ Formatos Detalhados

Para ver o formato detalhado de cada arquivo (colunas obrigatÃ³rias, exemplos, etc), consulte:

**ðŸ‘‰ [FORMATOS_ARQUIVOS.md](FORMATOS_ARQUIVOS.md)**

### Resumo RÃ¡pido:

#### 1. **cadastro_produtos.csv**
```csv
codigo,descricao,categoria,subcategoria,und_venda,curva_abc
1001,Produto A,Alimentos,GrÃ£os,UN,A
1002,Produto B,Bebidas,Refrigerantes,UN,B
```

**Colunas obrigatÃ³rias:**
- `codigo` (INTEGER)
- `descricao` (TEXT)

**Colunas opcionais:**
- `categoria`, `subcategoria`, `und_venda`, `curva_abc`

---

#### 2. **cadastro_fornecedores.csv**
```csv
codigo_fornecedor,nome_fornecedor,categoria,lead_time_dias
FORN001,Fornecedor ABC Ltda,Alimentos,30
FORN002,Distribuidora XYZ,Bebidas,14
```

**Colunas obrigatÃ³rias:**
- `codigo_fornecedor` (TEXT)
- `nome_fornecedor` (TEXT)

---

#### 3. **estoque_atual.csv**
```csv
cod_empresa,codigo,qtd_estoque,localizacao
1,1001,150,GÃ´ndola
1,1002,80,DepÃ³sito
```

**Colunas obrigatÃ³rias:**
- `cod_empresa` (INTEGER) - cÃ³digo da loja
- `codigo` (INTEGER) - cÃ³digo do produto
- `qtd_estoque` (DECIMAL)

---

#### 4. **historico_vendas.csv**
```csv
data,cod_empresa,codigo,qtd_venda,valor_venda
2024-01-01,1,1001,25,125.50
2024-01-01,1,1002,18,90.00
```

**Colunas obrigatÃ³rias:**
- `data` (DATE no formato YYYY-MM-DD)
- `cod_empresa` (INTEGER)
- `codigo` (INTEGER)
- `qtd_venda` (DECIMAL)

**Colunas opcionais:**
- `valor_venda` (DECIMAL)

âš ï¸ **IMPORTANTE:** Este pode ser o maior arquivo! O script importa em lotes (batch).

---

#### 5. **historico_estoque.csv**
```csv
data,cod_empresa,codigo,estoque_diario
2024-01-01,1,1001,150
2024-01-01,1,1002,80
```

**Colunas obrigatÃ³rias:**
- `data` (DATE)
- `cod_empresa` (INTEGER)
- `codigo` (INTEGER)
- `estoque_diario` (DECIMAL)

---

#### 6. **eventos_promocionais.csv**
```csv
nome_evento,tipo_evento,data_inicio,data_fim,impacto_estimado
Black Friday 2024,BlackFriday,2024-11-24,2024-11-30,35.5
Natal 2024,Natal,2024-12-15,2024-12-25,28.0
```

**Colunas obrigatÃ³rias:**
- `nome_evento` (TEXT)
- `data_inicio` (DATE)
- `data_fim` (DATE)

**Colunas opcionais:**
- `tipo_evento`, `impacto_estimado`

---

## ðŸš€ ImportaÃ§Ã£o dos Dados

### Passo 1: Configurar ConexÃ£o

Editar `database\importar_csvs.py` (linha 21-27):

```python
DB_CONFIG = {
    'host': 'localhost',
    'database': 'demanda_reabastecimento',
    'user': 'postgres',
    'password': 'SUA_SENHA_AQUI',  # ALTERAR!
    'port': 5432
}
```

### Passo 2: Instalar DependÃªncias

```cmd
pip install psycopg2-binary pandas openpyxl xlrd
```

**O que cada biblioteca faz:**
- `psycopg2-binary`: Conectar ao PostgreSQL
- `pandas`: Manipular dados
- `openpyxl`: Ler arquivos Excel modernos (.xlsx)
- `xlrd`: Ler arquivos Excel antigos (.xls)

### Passo 3: Rodar ImportaÃ§Ã£o

```cmd
cd C:\Users\valter.lino\Desktop\Treinamentos\VS\previsao-demanda

python database\importar_csvs.py
```

**O que acontece:**
1. âœ… Procura arquivos em CSV, XLSX ou XLS
2. âœ… Detecta encoding automaticamente (CSV)
3. âœ… Valida colunas obrigatÃ³rias
4. âœ… Processa/transforma dados
5. âœ… Insere em lotes de 1000 registros
6. âœ… Mostra progresso em tempo real

**SaÃ­da esperada:**
```
============================================================
   IMPORTAÃ‡ÃƒO DE DADOS PARA BANCO DE DADOS
============================================================

ðŸ“ DiretÃ³rio de dados: C:\...\data_import
ðŸ—„ï¸  Banco: demanda_reabastecimento@localhost
ðŸ“‹ Formatos aceitos: CSV, XLSX, XLS

âœ… Conectado ao banco 'demanda_reabastecimento'

============================================================
ðŸ“‚ Processando: cadastro_produtos.csv
============================================================
âœ… Lido: 245 registros
ðŸ”§ Preparando dados...
ðŸ’¾ Inserindo em 'cadastro_produtos'...
  âœ… 245 registros inseridos em cadastro_produtos
âœ… ImportaÃ§Ã£o concluÃ­da: 245 registros

...

============================================================
   RESUMO DA IMPORTAÃ‡ÃƒO
============================================================
Total de arquivos configurados: 9
âœ… Importados com sucesso: 7
âš ï¸  Pulados (nÃ£o encontrados): 2
âŒ Erros: 0
============================================================

ðŸŽ‰ ImportaÃ§Ã£o concluÃ­da!
```

---

## âœ… ValidaÃ§Ã£o

### Via pgAdmin:

1. Abrir pgAdmin 4
2. Navegar: Servers â†’ PostgreSQL â†’ Databases â†’ demanda_reabastecimento â†’ Schemas â†’ public â†’ Tables
3. Right-click em `cadastro_produtos` â†’ View/Edit Data â†’ All Rows
4. Verificar se os dados estÃ£o lÃ¡!

### Via SQL (Terminal):

```cmd
psql -U postgres -d demanda_reabastecimento
```

```sql
-- Contar registros em cada tabela
SELECT 'cadastro_produtos' as tabela, COUNT(*) FROM cadastro_produtos
UNION ALL
SELECT 'historico_vendas_diario', COUNT(*) FROM historico_vendas_diario
UNION ALL
SELECT 'historico_estoque_diario', COUNT(*) FROM historico_estoque_diario
UNION ALL
SELECT 'eventos_promocionais', COUNT(*) FROM eventos_promocionais;

-- Ver amostra de vendas
SELECT * FROM historico_vendas_diario
ORDER BY data DESC
LIMIT 10;

-- Ver estoque atual
SELECT
    e.cod_empresa,
    e.codigo,
    p.descricao,
    e.qtd_estoque
FROM estoque_atual e
JOIN cadastro_produtos p ON e.codigo = p.codigo
LIMIT 10;
```

### Atualizar Views Materializadas:

```sql
REFRESH MATERIALIZED VIEW vw_estoque_total;
REFRESH MATERIALIZED VIEW vw_vendas_mensais;

-- Verificar
SELECT * FROM vw_estoque_total LIMIT 10;
```

---

## ðŸ”Œ IntegraÃ§Ã£o com a Ferramenta

Agora que os dados estÃ£o no banco, precisamos conectar a ferramenta.

### 1. Instalar Biblioteca de ConexÃ£o

```cmd
pip install psycopg2-binary sqlalchemy
```

### 2. Criar MÃ³dulo de ConexÃ£o

Criar `core/database.py`:

```python
import psycopg2
from psycopg2.extras import RealDictCursor
import pandas as pd
from sqlalchemy import create_engine

DB_CONFIG = {
    'host': 'localhost',
    'database': 'demanda_reabastecimento',
    'user': 'postgres',
    'password': 'SUA_SENHA',
    'port': 5432
}

def get_connection():
    """Retorna conexÃ£o ao banco"""
    return psycopg2.connect(**DB_CONFIG, cursor_factory=RealDictCursor)

def query_to_dataframe(sql, params=None):
    """Executa query e retorna DataFrame"""
    engine = create_engine(
        f"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@"
        f"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}"
    )
    return pd.read_sql(sql, engine, params=params)

# Exemplo de uso
def buscar_vendas_produto(cod_empresa, codigo, data_inicio, data_fim):
    """Busca histÃ³rico de vendas de um produto"""
    sql = """
        SELECT data, qtd_venda, valor_venda
        FROM historico_vendas_diario
        WHERE cod_empresa = %s
          AND codigo = %s
          AND data BETWEEN %s AND %s
        ORDER BY data
    """
    return query_to_dataframe(sql, (cod_empresa, codigo, data_inicio, data_fim))
```

### 3. Modificar `daily_data_loader.py`

Em vez de ler CSV, buscar do banco:

```python
from core.database import query_to_dataframe

class DailyDataLoader:
    def carregar_do_banco(self, data_inicio, data_fim, lojas=None, produtos=None):
        """Carrega dados diÃ¡rios do banco"""
        sql = """
            SELECT
                data,
                cod_empresa,
                codigo,
                qtd_venda,
                estoque_diario
            FROM historico_vendas_diario v
            LEFT JOIN historico_estoque_diario e
              ON v.data = e.data
             AND v.cod_empresa = e.cod_empresa
             AND v.codigo = e.codigo
            WHERE v.data BETWEEN %s AND %s
        """

        params = [data_inicio, data_fim]

        if lojas:
            sql += " AND v.cod_empresa = ANY(%s)"
            params.append(lojas)

        if produtos:
            sql += " AND v.codigo = ANY(%s)"
            params.append(produtos)

        sql += " ORDER BY v.data, v.cod_empresa, v.codigo"

        return query_to_dataframe(sql, params)
```

### 4. Atualizar Endpoint de KPIs

No `app.py`, substituir dados mockados:

```python
from core.database import query_to_dataframe

@app.route('/api/kpis/dados', methods=['GET'])
def kpis_dados():
    visao = request.args.get('visao', 'mensal')

    # Buscar KPIs do banco
    if visao == 'mensal':
        sql = """
            SELECT
                TO_CHAR(data_ref, 'Mon/YY') as mes,
                AVG(wmape) as wmape,
                AVG(bias) as bias,
                AVG(taxa_ruptura) as taxa_ruptura,
                AVG(cobertura_media) as cobertura_media
            FROM kpis_historico
            WHERE tipo_periodo = 'mensal'
              AND data_ref >= CURRENT_DATE - INTERVAL '12 months'
            GROUP BY data_ref
            ORDER BY data_ref
        """
        df = query_to_dataframe(sql)

        wmape_mensal = df[['mes', 'wmape']].to_dict('records')
        bias_mensal = df[['mes', 'bias']].to_dict('records')
        # ...

    return jsonify({
        'metricas_atuais': {...},
        'series_temporais': {
            'wmape_mensal': wmape_mensal,
            'bias_mensal': bias_mensal,
            ...
        }
    })
```

---

## ðŸ“Š Performance e ManutenÃ§Ã£o

### Indexes (jÃ¡ criados no schema.sql):

âœ… Todas as colunas de data tÃªm Ã­ndice
âœ… Chaves estrangeiras tÃªm Ã­ndice
âœ… CombinaÃ§Ãµes freq

uentes (loja+produto+data) tÃªm Ã­ndice composto

### Particionamento:

âœ… `historico_vendas_diario` particionado por ANO
âœ… `historico_estoque_diario` particionado por ANO
âœ… Queries automÃ¡ticas usam apenas partiÃ§Ãµes necessÃ¡rias

### Views Materializadas:

Atualizar diariamente (via cron/job):

```sql
REFRESH MATERIALIZED VIEW CONCURRENTLY vw_estoque_total;
REFRESH MATERIALIZED VIEW CONCURRENTLY vw_vendas_mensais;
```

### Backup:

```cmd
# Backup completo
pg_dump -U postgres -d demanda_reabastecimento > backup_$(date +%Y%m%d).sql

# Restore
psql -U postgres -d demanda_reabastecimento < backup_20260107.sql
```

---

## ðŸŽ¯ Resumo - Checklist

- [ ] PostgreSQL instalado e rodando
- [ ] Banco `demanda_reabastecimento` criado
- [ ] Schema SQL executado (tabelas criadas)
- [ ] CSVs preparados na pasta `data_import`
- [ ] Script `importar_csvs.py` configurado (senha)
- [ ] ImportaÃ§Ã£o executada com sucesso
- [ ] Dados validados (queries de teste)
- [ ] Views materializadas atualizadas
- [ ] MÃ³dulo `core/database.py` criado
- [ ] Ferramenta integrada ao banco

---

## ðŸ’¡ PrÃ³ximos Passos

1. **Job de AtualizaÃ§Ã£o DiÃ¡ria:**
   - Script que importa vendas/estoque do dia anterior
   - Roda automaticamente todo dia Ã s 6h

2. **CÃ¡lculo AutomÃ¡tico de KPIs:**
   - Job semanal/mensal que calcula e armazena KPIs
   - Alimenta tabela `kpis_historico`

3. **API REST:**
   - Endpoints para inserÃ§Ã£o de dados via API
   - IntegraÃ§Ã£o com sistemas existentes

4. **Dashboard Tempo Real:**
   - WebSocket para atualizaÃ§Ã£o em tempo real
   - Alertas automÃ¡ticos

---

**Criado por:** Claude Code + Valter Lino
**Data:** Janeiro 2026
**VersÃ£o:** 1.0
